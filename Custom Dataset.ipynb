{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Custom Dataset.ipynb","provenance":[],"authorship_tag":"ABX9TyNqobuLQepoLNJVnIDJYFOm"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"x_0wXeoPyAZ_","colab_type":"text"},"source":["# Custom Dataset\n"]},{"cell_type":"markdown","metadata":{"id":"Yd2uY377yEP5","colab_type":"text"},"source":["그런데 torch.utils.data.Dataset을 상속받아 직접 커스텀 데이터셋(Custom Dataset)을 만드는 경우도 있습니다.    torch.utils.data.Dataset은 파이토치에서 데이터셋을 제공하는 추상 클래스입니다.  \n","Dataset을 상속받아 다음 메소드들을 오버라이드 하여 커스텀 데이터셋을 만들어보겠습니다. \n","\n","--------------------\n","커스텀 데이터셋을 만들 때, 일단 가장 기본적인 뼈대는 아래와 같습니다. 여기서 필요한 기본적인 define은 3개입니다."]},{"cell_type":"markdown","metadata":{"id":"9iRKke0_yShl","colab_type":"text"},"source":["```python\n","class CustomDataset(torch.utils.data.Dataset):\n","    def __init__(self):\n","        #데이터셋의 전처리를 해주는 부분\n","\n","    def __len__(self):\n","        #데이터셋의 길이. 즉, 총 샘플의 수를 적어주는 부분\n","\n","    def __getitem__(self, idx):\n","        #데이터셋에서 특정 1개의 샘플을 가져오는 함수\n","\n","```\n","\n","`len(dataset)`을 했을 때 데이터셋의 크기를 리턴할 len  \n","\n","`dataset[i]`을 했을 때 i번째 샘플을 가져오도록 하는 인덱싱을 위한 get_item"]},{"cell_type":"markdown","metadata":{"id":"T3k16TvBzC61","colab_type":"text"},"source":["# Linear Regression(custom_dataset)"]},{"cell_type":"code","metadata":{"id":"v6kO9Go9zb-V","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2JzRerO1z3BQ","colab_type":"code","colab":{}},"source":["class CustomDataset(Dataset):\n","    def __init__(self):\n","\n","        self.x_data = [[73, 80, 75],\n","                   [93, 88, 93],\n","                   [89, 91, 90],\n","                   [96, 98, 100],\n","                   [73, 66, 70]]\n","        self.y_data = [[152], [185], [180], [196], [142]]\n","\n","    #총 데이터의 개수 리턴\n","\n","    def __len__(self):\n","\n","        return len(self.x_data)\n","\n","    # 인덱스를 입력받아 그에 맵핑되는 입출력 데이터를 파이토치의 Tensor 형태로 리턴\n","    def __getitem__(self, idx):\n","        x= torch.FloatTensor(self.x_data[idx])\n","        y= torch.FloatTensor(self.y_data[idx])\n","\n","        return x, y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"S3bDcdTMzo9k","colab_type":"code","colab":{}},"source":["dataset = CustomDataset()\n","dataloader = DataLoader(dataset, batch_size = 2, shuffle = True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8DPq2oj5z1QA","colab_type":"code","colab":{}},"source":["model = torch.nn.Linear(3,1)\n","optimizer = torch.optim.SGD(model.parameters(), lr = 1e-5)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UIFp2OvH8FCM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"5c5ce957-97c5-4158-9a4a-c0d579997f91","executionInfo":{"status":"ok","timestamp":1584691204261,"user_tz":-540,"elapsed":1043,"user":{"displayName":"g1moon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjZL5BQYZB4jmoREa2K_Tlx6hwQ1IwtV7mYVb34=s64","userId":"16307972960386931414"}}},"source":["nb_epochs = 20\n","\n","for epoch in range(nb_epochs+1):\n","    for batch_idx, samples in enumerate(dataloader):\n","\n","        x_train, y_train = samples\n","        \n","        prediction = model(x_train)\n","\n","        cost = F.mse_loss(prediction, y_train)\n","\n","        optimizer.zero_grad()\n","        cost.backward()\n","        optimizer.step()\n","\n","\n","        print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(\n","        epoch, nb_epochs, batch_idx+1, len(dataloader),\n","        cost.item()\n","        ))"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Epoch    0/20 Batch 1/3 Cost: 51632.304688\n","Epoch    0/20 Batch 2/3 Cost: 9234.525391\n","Epoch    0/20 Batch 3/3 Cost: 2142.804443\n","Epoch    1/20 Batch 1/3 Cost: 1532.116333\n","Epoch    1/20 Batch 2/3 Cost: 500.084900\n","Epoch    1/20 Batch 3/3 Cost: 160.805038\n","Epoch    2/20 Batch 1/3 Cost: 50.968513\n","Epoch    2/20 Batch 2/3 Cost: 14.024593\n","Epoch    2/20 Batch 3/3 Cost: 2.508523\n","Epoch    3/20 Batch 1/3 Cost: 0.895715\n","Epoch    3/20 Batch 2/3 Cost: 1.595286\n","Epoch    3/20 Batch 3/3 Cost: 1.360731\n","Epoch    4/20 Batch 1/3 Cost: 0.196957\n","Epoch    4/20 Batch 2/3 Cost: 0.538352\n","Epoch    4/20 Batch 3/3 Cost: 0.823863\n","Epoch    5/20 Batch 1/3 Cost: 0.711041\n","Epoch    5/20 Batch 2/3 Cost: 0.268103\n","Epoch    5/20 Batch 3/3 Cost: 0.419364\n","Epoch    6/20 Batch 1/3 Cost: 0.501468\n","Epoch    6/20 Batch 2/3 Cost: 0.431142\n","Epoch    6/20 Batch 3/3 Cost: 0.068601\n","Epoch    7/20 Batch 1/3 Cost: 0.386956\n","Epoch    7/20 Batch 2/3 Cost: 0.872392\n","Epoch    7/20 Batch 3/3 Cost: 0.008539\n","Epoch    8/20 Batch 1/3 Cost: 0.124964\n","Epoch    8/20 Batch 2/3 Cost: 0.473342\n","Epoch    8/20 Batch 3/3 Cost: 0.650694\n","Epoch    9/20 Batch 1/3 Cost: 0.478691\n","Epoch    9/20 Batch 2/3 Cost: 0.391311\n","Epoch    9/20 Batch 3/3 Cost: 0.459572\n","Epoch   10/20 Batch 1/3 Cost: 0.161734\n","Epoch   10/20 Batch 2/3 Cost: 0.883803\n","Epoch   10/20 Batch 3/3 Cost: 0.432488\n","Epoch   11/20 Batch 1/3 Cost: 0.461119\n","Epoch   11/20 Batch 2/3 Cost: 0.426462\n","Epoch   11/20 Batch 3/3 Cost: 0.294881\n","Epoch   12/20 Batch 1/3 Cost: 0.465648\n","Epoch   12/20 Batch 2/3 Cost: 0.450799\n","Epoch   12/20 Batch 3/3 Cost: 0.074977\n","Epoch   13/20 Batch 1/3 Cost: 0.384801\n","Epoch   13/20 Batch 2/3 Cost: 0.231097\n","Epoch   13/20 Batch 3/3 Cost: 0.599292\n","Epoch   14/20 Batch 1/3 Cost: 0.418792\n","Epoch   14/20 Batch 2/3 Cost: 0.385933\n","Epoch   14/20 Batch 3/3 Cost: 0.414575\n","Epoch   15/20 Batch 1/3 Cost: 0.054913\n","Epoch   15/20 Batch 2/3 Cost: 1.000436\n","Epoch   15/20 Batch 3/3 Cost: 0.614507\n","Epoch   16/20 Batch 1/3 Cost: 0.265486\n","Epoch   16/20 Batch 2/3 Cost: 0.425158\n","Epoch   16/20 Batch 3/3 Cost: 0.479922\n","Epoch   17/20 Batch 1/3 Cost: 0.120668\n","Epoch   17/20 Batch 2/3 Cost: 0.460820\n","Epoch   17/20 Batch 3/3 Cost: 0.691438\n","Epoch   18/20 Batch 1/3 Cost: 0.416297\n","Epoch   18/20 Batch 2/3 Cost: 0.362179\n","Epoch   18/20 Batch 3/3 Cost: 0.597262\n","Epoch   19/20 Batch 1/3 Cost: 0.446314\n","Epoch   19/20 Batch 2/3 Cost: 0.447286\n","Epoch   19/20 Batch 3/3 Cost: 0.073687\n","Epoch   20/20 Batch 1/3 Cost: 0.424379\n","Epoch   20/20 Batch 2/3 Cost: 0.167738\n","Epoch   20/20 Batch 3/3 Cost: 0.582263\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KMZvko7J8hTt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"5ae40825-f85b-49c2-e4ea-0f7f386efa1e","executionInfo":{"status":"ok","timestamp":1584691218649,"user_tz":-540,"elapsed":956,"user":{"displayName":"g1moon","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjZL5BQYZB4jmoREa2K_Tlx6hwQ1IwtV7mYVb34=s64","userId":"16307972960386931414"}}},"source":["# 임의의 입력 [73, 80, 75]를 선언\n","new_var =  torch.FloatTensor([[73, 80, 75]]) \n","# 입력한 값 [73, 80, 75]에 대해서 예측값 y를 리턴받아서 pred_y에 저장\n","pred_y = model(new_var) \n","print(\"훈련 후 입력이 73, 80, 75일 때의 예측값 :\", pred_y) "],"execution_count":25,"outputs":[{"output_type":"stream","text":["훈련 후 입력이 73, 80, 75일 때의 예측값 : tensor([[151.9664]], grad_fn=<AddmmBackward>)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OoUHFa2y8hXe","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DOb41R5C8hYV","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wNzhAwF_8hZX","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"glDI2YCa8hau","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_PV9y5IY8hb6","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rza5h4jz8hdG","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VoivdWok8heT","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8a1k-AkM8hfd","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oF3Y7uYO8hgp","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Xpq_DdS8hh1","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ckLnP71W8hjB","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NLST9hr78hkQ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xPPYU06y8hlZ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"k7boQ7A98hmb","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DCQHdMsP8hne","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"p5EjSJCU8hof","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LeDxwAAI8hpj","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}